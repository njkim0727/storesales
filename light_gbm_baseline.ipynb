{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"Root Mean Squared Logarithmic Error\"\"\"\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n",
    "\n",
    "\n",
    "# input, target, pca 주성분 개수를 입력 받아 dataframe의 주성분 분석을 통해, n개의 주성분으로 구성된 새로운 데이터 세트를 만들어 내는 함수\n",
    "def convert_pca_n_df (df_x, df_y, n):\n",
    "    pca = PCA(n_components=df_x.shape[1])  # 모든 성분을 유지\n",
    "    X_pca = pca.fit_transform(df_x)\n",
    "    \n",
    "    # 성분별 설명 분산 비율\n",
    "    # explained_variance = pca.explained_variance_ratio_\n",
    "    \n",
    "    # PCA 성분들과 sales 사이의 상관관계 확인\n",
    "    pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(df_x.shape[1])])\n",
    "    pca_df['sales'] = df_y.values\n",
    "    \n",
    "    # 성분들과 sales 간의 상관계수 계산\n",
    "    correlations = pca_df.corr()['sales'].drop('sales').abs()\n",
    "    \n",
    "    # sales에 가장 큰 영향을 주는 성분들을 선택\n",
    "    important_components = correlations.sort_values(ascending=False)\n",
    "    \n",
    "    # 상위 몇 개의 성분을 기준으로 features 축소\n",
    "    n_important = n  # 상위 5개의 중요한 성분을 선택하는 경우\n",
    "    selected_components = important_components.index[:n_important]\n",
    "    df_result = pca_df[selected_components]\n",
    "    \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리(Label Encoding)되 데이터 로드\n",
    "#X_train = pd.read_csv('TestData/train_data_label_encoded.csv')\n",
    "X_train = pd.read_csv('TestData/X_test_pca_42.csv')\n",
    "y_train = pd.read_csv('TestData/train_target.csv').iloc[:, 0]\n",
    "# X_val = pd.read_csv('TestData/val_data_label_encoded.csv')\n",
    "X_val = pd.read_csv('TestData/X_val_pca_42.csv')\n",
    "y_val = pd.read_csv('TestData/val_target.csv').iloc[:, 0]\n",
    "\n",
    "# 학습에 사용하지 않을 컬럼 삭제\n",
    "# X_train.drop(['id', 'date', 'date_type', 'day'], axis=1, inplace=True)\n",
    "# X_val.drop(['id', 'date', 'date_type', 'day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 주성분 분석 및 sales와의 상관관계 분석을 통해 feature 축소\n",
    "\n",
    "# n=10 개의 주성분 추출\n",
    "X_train_pca = convert_pca_n_df (X_train, y_train, 10)\n",
    "X_val_pca = convert_pca_n_df (X_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 모델 생성\n",
    "model = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GVSearchCV로 LGBMRegressor 모델을 최적화하기 위한 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 2945646, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 355.629570\n",
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 127}\n",
      "Best Score: -2.2658357253063492\n",
      "RMSLE: 2.05987620647148\n"
     ]
    }
   ],
   "source": [
    "# 모델을 평가하기 위한 rmsle 스코어 함수 생성\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=rmsle_scorer, verbose=1, n_jobs=-1)\n",
    "\n",
    "# GridSearchCV 학습\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# 최적 하이퍼파라미터 및 성능 출력\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# 최적 모델로 테스트 데이터 평가\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_val_pca)\n",
    "y_pred = np.clip(y_pred, a_min=0, a_max=None)\n",
    "\n",
    "# Calculate RMSLE\n",
    "score = rmsle(y_val, y_pred)\n",
    "print(\"RMSLE:\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
